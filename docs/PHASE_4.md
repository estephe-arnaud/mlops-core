# üü° Phase 4 : Exp√©rimentation - Tracking MLflow + Versioning DVC

## üß≠ Navigation

| ‚Üê Pr√©c√©dent | Suivant ‚Üí |
|-------------|-----------|
| [Phase 3 : Infrastructure](PHASE_3.md) | [Phase 5 : Orchestration](PHASE_5.md) |
| [Retour au README](../README.md) | [Toutes les phases](.) |

## üìã Table des Mati√®res

1. [Objectif de la Phase](#-objectif-de-la-phase)
2. [T√¢ches √† Accomplir](#-t√¢ches-√†-accomplir)
3. [Livrables Attendus](#-livrables-attendus)
4. [Impl√©mentation Pr√©vue](#-impl√©mentation-pr√©vue)
5. [Outils √† Utiliser](#-outils-√†-utiliser)
6. [M√©triques Attendues](#-m√©triques-attendues)
7. [Ressources](#-ressources)
8. [Progression](#-progression)
9. [Objectifs de Validation](#-objectifs-de-validation)
10. [Interface MLflow](#-interface-mlflow)
11. [Pipeline DVC](#-pipeline-dvc)
12. [Impl√©mentation Compl√®te](#-impl√©mentation-compl√®te)
13. [Guide d'Utilisation](#-guide-dutilisation)
14. [Exemples d'Exp√©riences MLflow](#-exemples-dexp√©riences-mlflow)
15. [Versioning des Donn√©es (DVC)](#-versioning-des-donn√©es-dvc)
16. [R√©sultats Attendus](#-r√©sultats-attendus)
17. [Workflow Complet : Entra√Ænement ‚Üí D√©ploiement](#-workflow-complet-entra√Ænement--d√©ploiement)
18. [D√©pannage](#-d√©pannage)
19. [Validation des Objectifs](#-validation-des-objectifs)

---

## üéØ Objectif de la Phase

**Traquer et versionner les exp√©riences ML localement pour la reproductibilit√©**

### ‚ùì Questions Cl√©s
- Comment tracer les exp√©riences (MLflow) ?
- Comment versionner le dataset et le pipeline (DVC) ?

### ‚è±Ô∏è R√©partition des Heures (20h)
- **7h** ‚Üí Int√©grer MLflow Tracking pour logguer les hyperparam√®tres, m√©triques et le mod√®le
- **7h** ‚Üí Impl√©menter DVC pour versionner le dataset et le pipeline de pr√©-traitement
- **6h** ‚Üí Finalisation Projet 1 : documentation + vid√©o d√©mo

---

## üìã T√¢ches √† Accomplir

### 1. üìä MLflow Tracking
- Int√©grer MLflow dans le script d'entra√Ænement (src/training/train.py)
- Logger les hyperparam√®tres et m√©triques
- Sauvegarder les mod√®les et artifacts
- Interface web MLflow UI

### 2. üîÑ DVC (Data Version Control)
- Initialiser DVC dans le projet
- Versionner le dataset Iris
- Cr√©er un pipeline de pr√©-traitement
- G√©rer les d√©pendances entre √©tapes

### 3. üìö Documentation et D√©mo
- R√©diger un README complet
- Cr√©er des sch√©mas d'architecture
- Enregistrer une vid√©o de d√©monstration
- Finaliser le Projet 1

## üì¶ Livrables Attendus

### Structure MLflow
```
mlruns/                    # Dossier MLflow (g√©n√©r√©)
‚îú‚îÄ‚îÄ 0/                    # Experiments
‚îÇ   ‚îî‚îÄ‚îÄ runs/             # Runs individuels
‚îî‚îÄ‚îÄ models/               # Mod√®les enregistr√©s
```

### Structure DVC
```
.dvc/                     # Configuration DVC
‚îú‚îÄ‚îÄ config               # Configuration
‚îú‚îÄ‚îÄ cache/               # Cache des donn√©es
‚îî‚îÄ‚îÄ tmp/                 # Fichiers temporaires

data/                    # Donn√©es versionn√©es
‚îú‚îÄ‚îÄ raw/                 # Donn√©es brutes
‚îú‚îÄ‚îÄ processed/           # Donn√©es trait√©es
‚îî‚îÄ‚îÄ .gitignore          # Ignorer les gros fichiers

dvc.yaml                 # Pipeline DVC
dvc.lock                 # Verrouillage des versions
```

### Documentation
- **README.md** : Documentation compl√®te du projet
- **ARCHITECTURE.md** : Sch√©mas et architecture
- **DEMO_VIDEO.mp4** : Vid√©o de d√©monstration (3-5 min)

## üöÄ Impl√©mentation Pr√©vue

### MLflow Integration
```python
# src/training/train.py avec MLflow
import mlflow
import mlflow.sklearn

def train_model():
    with mlflow.start_run():
        # Log des param√®tres
        mlflow.log_param("algorithm", "RandomForest")
        mlflow.log_param("n_estimators", 100)
        mlflow.log_param("max_depth", 10)
        
        # Entra√Ænement du mod√®le
        model = RandomForestClassifier(n_estimators=100, max_depth=10)
        model.fit(X_train, y_train)
        
        # √âvaluation
        accuracy = model.score(X_test, y_test)
        mlflow.log_metric("accuracy", accuracy)
        
        # Sauvegarde du mod√®le
        mlflow.sklearn.log_model(model, "model")
        
        return model
```

### DVC Pipeline
```yaml
# dvc.yaml
stages:
  prepare:
    cmd: python -m src.data.prepare
    deps:
    - data/raw/iris.csv
    outs:
    - data/processed/train.csv
    - data/processed/test.csv
    
  train:
    cmd: python -m src.training.train
    deps:
    - data/processed/train.csv
    - data/processed/test.csv
    - src/training/train.py
    - src/evaluation/evaluate.py
    outs:
    - models/metadata.json
    metrics:
    - models/metrics.json
    # Note : Le mod√®le ML est sauvegard√© dans MLflow (mlruns/), pas dans models/
```

## üõ†Ô∏è Outils √† Utiliser

### MLflow
- **Tracking** : Logging des exp√©riences
- **Models** : Gestion des mod√®les
- **UI** : Interface web pour visualisation
- **Storage** : Fichier local (puis cloud)

### DVC
- **Data Versioning** : Git-like pour les donn√©es
- **Pipeline** : Orchestration des √©tapes
- **Cache** : Stockage efficace
- **Remote** : Stockage distant (optionnel)

### Visualisation
- **MLflow UI** : Interface web des exp√©riences
- **DVC Plots** : Visualisation des m√©triques
- **Draw.io** : Sch√©mas d'architecture

## üìä M√©triques Attendues

| Composant | Objectif |
|-----------|----------|
| **MLflow Runs** | 5+ exp√©riences logg√©es |
| **DVC Pipeline** | 2+ √©tapes (prepare, train) |
| **Data Versioning** | Dataset et mod√®les versionn√©s |
| **Reproductibilit√©** | Pipeline reproductible |

## üîó Ressources

- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [DVC Documentation](https://dvc.org/doc)
- [MLflow Quickstart](https://mlflow.org/docs/latest/getting-started/index.html)
- [DVC Tutorial](https://dvc.org/doc/start)

## üìà Progression

### √âtape 1 : MLflow (7h) ‚úÖ
- [x] Installation et configuration MLflow
- [x] Int√©gration dans src/training/train.py
- [x] Logging des param√®tres et m√©triques
- [x] Sauvegarde des mod√®les
- [x] Interface web MLflow UI

### √âtape 2 : DVC (7h) ‚úÖ
- [x] Installation et initialisation DVC
- [x] Versioning du dataset
- [x] Cr√©ation du pipeline dvc.yaml
- [x] Gestion des d√©pendances
- [x] Tests de reproductibilit√©

### √âtape 3 : Finalisation (6h) ‚úÖ
- [x] Documentation compl√®te
- [x] Sch√©mas d'architecture
- [x] Vid√©o de d√©monstration (√† faire selon besoins)
- [x] Validation du Projet 1

## üéØ Objectifs de Validation

- [x] MLflow UI accessible et fonctionnel
- [x] Exp√©riences logg√©es avec param√®tres/m√©triques
- [x] DVC pipeline reproductible
- [x] Dataset et mod√®les versionn√©s
- [x] Documentation compl√®te
- [ ] Vid√©o de d√©monstration enregistr√©e (optionnel)

## üìä Interface MLflow

### Fonctionnalit√©s √† Impl√©menter
- **Experiments** : Organisation des runs
- **Runs** : D√©tails de chaque exp√©rience
- **Models** : Gestion des mod√®les
- **Artifacts** : Fichiers associ√©s
- **Metrics** : Graphiques des m√©triques

### M√©triques √† Logger
- **Accuracy** : Pr√©cision du mod√®le
- **Precision** : Pr√©cision par classe
- **Recall** : Rappel par classe
- **F1-Score** : Score F1 par classe
- **Confusion Matrix** : Matrice de confusion

## üîÑ Pipeline DVC

### √âtapes du Pipeline
1. **Prepare** : Pr√©paration des donn√©es
2. **Train** : Entra√Ænement du mod√®le
3. **Evaluate** : √âvaluation et m√©triques
4. **Deploy** : Pr√©paration du d√©ploiement

### Gestion des D√©pendances
- **Data** : Dataset ‚Üí Train/Test
- **Model** : Train ‚Üí Model + Metadata
- **Metrics** : Evaluate ‚Üí Metrics JSON

## üìö Documentation √† Cr√©er

### README Principal
- Vue d'ensemble du projet
- Instructions d'installation
- Guide d'utilisation
- Architecture et sch√©mas

### Documentation Technique
- Configuration MLflow
- Pipeline DVC
- Proc√©dures de d√©ploiement
- Troubleshooting

### Vid√©o de D√©monstration
- **Dur√©e** : 3-5 minutes
- **Contenu** : Installation, utilisation, r√©sultats
- **Format** : Loom ou OBS Studio
- **Objectif** : D√©monstration compl√®te du Projet 1

---

---

## ‚úÖ Impl√©mentation Compl√®te

### √âtape 1 : MLflow Tracking ‚úÖ

#### Installation
MLflow a √©t√© ajout√© aux d√©pendances dans `pyproject.toml` :
```toml
mlflow = "^2.9.2"
```

#### Int√©gration dans training/train.py
Le script `src/training/train.py` a √©t√© modifi√© pour int√©grer MLflow :

**Fonctionnalit√©s impl√©ment√©es** :
- ‚úÖ Tracking des hyperparam√®tres (n_estimators, max_depth, random_state, test_size)
- ‚úÖ Logging des m√©triques globales (accuracy, precision, recall, f1-score)
- ‚úÖ Logging des m√©triques par classe (precision, recall, f1-score pour chaque classe)
- ‚úÖ Sauvegarde de la confusion matrix comme artifact
- ‚úÖ Enregistrement du mod√®le via `mlflow.sklearn.log_model()`
- ‚úÖ Sauvegarde des m√©tadonn√©es comme artifact JSON

**Utilisation** :
```python
from src.training.train import train_model

# MLflow est toujours activ√©
model, metadata = train_model(n_estimators=100, max_depth=10)

# Le mod√®le est sauvegard√© dans MLflow (mlruns/)
# Les m√©tadonn√©es (metadata.json) contiennent l'URI MLflow pour charger le mod√®le
```

#### Interface MLflow UI
Lancer l'interface web :
```bash
make mlflow-ui
# Ou directement
poetry run mlflow ui --host 127.0.0.1 --port 5000
```

Acc√®s : http://localhost:5000

**Fonctionnalit√©s disponibles** :
- Visualisation des exp√©riences
- Comparaison des runs
- Graphiques des m√©triques
- T√©l√©chargement des mod√®les
- Visualisation des artifacts

### √âtape 2 : DVC Pipeline ‚úÖ

#### Installation
DVC a √©t√© ajout√© aux d√©pendances dans `pyproject.toml` :
```toml
dvc = {extras = ["gs", "s3", "azure", "oss", "ssh", "hdfs", "webdav", "gdrive"], version = "^3.41.0"}
```

#### Structure des donn√©es
```
data/
‚îú‚îÄ‚îÄ raw/              # Dataset brut (versionn√© avec DVC)
‚îÇ   ‚îî‚îÄ‚îÄ iris.csv
‚îî‚îÄ‚îÄ processed/        # Donn√©es trait√©es (g√©n√©r√©es)
    ‚îú‚îÄ‚îÄ train.csv
    ‚îî‚îÄ‚îÄ test.csv
```

#### Script de pr√©paration
Le script `src/data/prepare.py` :
- Charge le dataset Iris depuis scikit-learn
- Cr√©e un DataFrame pandas
- Lit les param√®tres depuis `params.yaml` via `src/config.py` (validation Pydantic)
- Divise en train/test avec les param√®tres configur√©s
- Sauvegarde dans `data/raw/` et `data/processed/`

#### Configuration centralis√©e
Le module `src/config.py` :
- Lit et valide les param√®tres depuis `params.yaml` avec Pydantic
- Validation type-safe des hyperparam√®tres et param√®tres de donn√©es
- Valeurs par d√©faut si `params.yaml` est absent
- Pattern singleton pour √©viter les rechargements multiples

#### Pipeline DVC
Le fichier `dvc.yaml` d√©finit le pipeline :

**1. Prepare**
- Commande : `poetry run python -m src.data.prepare`
- D√©pendances : `src/data/prepare.py`, `src/config.py`
- Param√®tres : `data.test_size`, `data.random_state` (depuis `params.yaml`)
- Sorties : `data/raw/iris.csv`, `data/processed/train.csv`, `data/processed/test.csv`

**2. Train**
- Commande : `poetry run python -m src.training.train`
- D√©pendances : `data/processed/train.csv`, `data/processed/test.csv`, `src/training/train.py`, `src/evaluation/evaluate.py`, `src/config.py`
- Param√®tres : `train.n_estimators`, `train.max_depth`, `train.random_state`, `train.test_size` (depuis `params.yaml`)
- Sorties : `models/metadata.json` (contient l'URI MLflow pour charger le mod√®le)
- M√©triques : `models/metrics.json`
- **Mod√®le ML** : Sauvegard√© dans MLflow (`mlruns/`), charg√© via l'URI dans `metadata.json`

#### Commandes DVC

**Initialisation** :
```bash
make dvc-init
# Ou directement
poetry run dvc init
```

**Ex√©cution du pipeline** :
```bash
make dvc-repro
# Ou directement
poetry run dvc repro
```

**Exp√©rimenter avec des param√®tres personnalis√©s** :
```bash
# Tester diff√©rents param√®tres sans modifier params.yaml
poetry run dvc exp run -S train.n_estimators=200 -S train.max_depth=10

# Comparer les r√©sultats dans MLflow
make mlflow-ui
```

> **üí° Note** : `dvc repro` r√©ex√©cute le pipeline avec les param√®tres de `params.yaml`. Pour tester diff√©rents param√®tres sans modifier le fichier, utilisez `dvc exp run -S`.

**V√©rifier l'√©tat** :
```bash
make dvc-status
# Ou directement
poetry run dvc status
```

**Visualiser le pipeline** :
```bash
make dvc-pipeline
# Ou directement
poetry run dvc dag
```

#### Workflow Standard DVC avec Git

**Principe** : DVC utilise un seul fichier `params.yaml` versionn√© dans Git. Les diff√©rentes configurations sont g√©r√©es via des branches Git.

**Workflow recommand√©** :

1. **Cr√©er une branche pour une nouvelle exp√©rience** :
```bash
git checkout -b experiment/high-n-estimators
```

2. **Modifier params.yaml directement** :
```yaml
# params.yaml
data:
  test_size: 0.2
  random_state: 42

train:
  n_estimators: 200  # Modifi√© pour l'exp√©rience
  max_depth: 10
```

3. **Ex√©cuter le pipeline** :
```bash
make dvc-repro
# ou directement: dvc repro
```

4. **MLflow track automatiquement les m√©triques** :
```bash
# Comparer dans MLflow UI
make mlflow-ui
# Ouvrir http://localhost:5000
```

5. **Commit si r√©sultats int√©ressants** :
```bash
git add params.yaml dvc.lock
git commit -m "Experiment: n_estimators=200, max_depth=10"
git push origin experiment/high-n-estimators
```

6. **Revenir √† main pour une autre exp√©rience** :
```bash
git checkout main
```

**Tests rapides sans modifier params.yaml** :

Pour des tests rapides sans cr√©er de branche :
```bash
# Surcharger des param√®tres sp√©cifiques avec 'dvc exp run'
# Note : 'dvc repro' ne supporte pas l'option -S, utilisez 'dvc exp run' √† la place
poetry run dvc exp run -S train.n_estimators=200 -S train.max_depth=10
```

> **üí° Diff√©rence entre `dvc repro` et `dvc exp run`** :
> - `dvc repro` : R√©ex√©cute le pipeline avec les param√®tres actuels de `params.yaml` (pas d'option `-S`)
> - `dvc exp run` : Permet de tester diff√©rents param√®tres avec `-S` sans modifier `params.yaml` (exp√©rimentations)

**Versioning des configurations** :

- Chaque commit de `params.yaml` repr√©sente une version de configuration
- Utiliser `git log params.yaml` pour voir l'historique des exp√©riences
- DVC suit automatiquement les changements de `params.yaml` via `dvc.lock`

**Pourquoi un seul params.yaml ?**

- ‚úÖ Standard DVC : DVC lit toujours `params.yaml` par d√©faut
- ‚úÖ Versioning clair : Git g√®re l'historique des configurations
- ‚úÖ Reproductibilit√© : Chaque commit = configuration reproductible
- ‚úÖ Pas de duplication : √âvite la d√©synchronisation entre fichiers

**Alternative (non recommand√©e)** :

Utiliser des branches Git est la pratique recommand√©e pour g√©rer diff√©rentes configurations de param√®tres.

### √âtape 3 : Int√©gration Compl√®te ‚úÖ

#### Configuration centralis√©e avec Pydantic ‚úÖ
Le module `src/config.py` a √©t√© cr√©√© pour :
- ‚úÖ Lire et valider les param√®tres depuis `params.yaml`
- ‚úÖ Validation type-safe avec Pydantic (contraintes, types)
- ‚úÖ Gestion d'erreurs robuste avec valeurs par d√©faut
- ‚úÖ Pattern singleton pour performance
- ‚úÖ Factorisation des param√®tres communs (DRY)

#### Scripts am√©lior√©s
Les scripts `prepare.py` et `train.py` :
- ‚úÖ Utilisent `get_config()` pour lire les param√®tres depuis `params.yaml`
- ‚úÖ Param√®tres surchargeables en arguments si n√©cessaire
- ‚úÖ Logging structur√© pour tra√ßabilit√©
- ‚úÖ Compatible avec MLflow et DVC simultan√©ment

#### Commandes Makefile
Nouvelles commandes ajout√©es :

**MLflow** :
- `make mlflow-ui` : Lancer l'interface MLflow
- `make mlflow-experiments` : Lister les exp√©riences

**DVC** :
- `make dvc-init` : Initialiser DVC
- `make dvc-repro` : R√©ex√©cuter le pipeline
- `make dvc-status` : V√©rifier l'√©tat
- `make dvc-push` : Pousser les donn√©es (si remote configur√©)
- `make dvc-pull` : T√©l√©charger les donn√©es
- `make dvc-pipeline` : Afficher le pipeline

## üöÄ Guide d'Utilisation

### Workflow Complet

#### 1. Installation
```bash
# Installer les d√©pendances (inclut MLflow et DVC)
make install
```

#### 2. Pr√©parer les donn√©es (DVC)
```bash
# Ex√©cuter l'√©tape prepare du pipeline
poetry run dvc repro prepare

# Ou ex√©cuter directement
poetry run python -m src.data.prepare
```

#### 3. Entra√Æner le mod√®le avec MLflow
```bash
# Entra√Æner avec tracking MLflow
make train

# Ou avec des hyperparam√®tres personnalis√©s
poetry run python -c "
from src.training.train import train_model
train_model(n_estimators=150, max_depth=15)
"
```

#### 4. Visualiser les r√©sultats
```bash
# Lancer MLflow UI
make mlflow-ui

# Ouvrir http://localhost:5000 dans le navigateur
```

#### 5. Ex√©cuter le pipeline complet (DVC)
```bash
# Ex√©cuter toutes les √©tapes
make dvc-repro

# V√©rifier l'√©tat
make dvc-status
```

### Exemples d'Exp√©riences MLflow

#### Exp√©rience 1 : Mod√®le de base
```bash
poetry run python -c "
from src.training.train import train_model
train_model(n_estimators=100, max_depth=None)
"
```

#### Exp√©rience 2 : Mod√®le avec profondeur limit√©e
```bash
poetry run python -c "
from src.training.train import train_model
train_model(n_estimators=100, max_depth=5)
"
```

#### Exp√©rience 3 : Plus d'arbres
```bash
poetry run python -c "
from src.training.train import train_model
train_model(n_estimators=200, max_depth=10)
"
```

### Versioning des Donn√©es (DVC)

#### Ajouter des donn√©es au tracking
```bash
# Ajouter le dataset brut
poetry run dvc add data/raw/iris.csv

# Commit dans Git
git add data/raw/iris.csv.dvc .gitignore
git commit -m "Add iris dataset"
```

#### Changer de version de donn√©es
```bash
# Modifier les donn√©es
# ...

# Mettre √† jour DVC
poetry run dvc add data/raw/iris.csv

# Commit
git add data/raw/iris.csv.dvc
git commit -m "Update dataset version"
```

## üìä R√©sultats Attendus

### MLflow
- ‚úÖ Exp√©riences logg√©es dans `mlruns/`
- ‚úÖ Mod√®les enregistr√©s et versionn√©s
- ‚úÖ M√©triques trac√©es et comparables
- ‚úÖ Interface web fonctionnelle

### DVC
- ‚úÖ Pipeline reproductible
- ‚úÖ Donn√©es versionn√©es
- ‚úÖ D√©pendances g√©r√©es automatiquement
- ‚úÖ Cache pour acc√©l√©rer les r√©ex√©cutions

## üöÄ Workflow Complet : Entra√Ænement ‚Üí D√©ploiement

### 1. Entra√Ænement Local

```bash
# 1. Entra√Æner le mod√®le localement
make train

# 2. V√©rifier les fichiers g√©n√©r√©s
ls -la models/
# - metadata.json (contient mlflow_run_id, mlflow_run_uri, etc.)
# - metrics.json

# 3. V√©rifier MLflow local
ls -la mlruns/
# Structure : mlruns/<experiment_id>/<run_id>/artifacts/model/
```

### 2. Cr√©er les Ressources GCP

> ‚ö†Ô∏è **Important** : Cr√©er d'abord les ressources GCP (bucket, VM, etc.) avant d'uploader les fichiers.

```bash
# 1. Configurer Terraform (voir docs/PHASE_3.md pour les d√©tails)
make terraform-init
# ou directement
terraform -chdir=terraform init

make terraform-plan
# ou directement
terraform -chdir=terraform plan

make terraform-apply
# ou directement
terraform -chdir=terraform apply

# 2. R√©cup√©rer le nom du bucket cr√©√©
BUCKET_NAME=$(terraform -chdir=terraform output -raw bucket_name)
```

### 3. Uploader les Fichiers vers GCS

```bash
# 1. Identifier le run_id √† d√©ployer
cat models/metadata.json | grep mlflow_run_id

# 2. Uploader mlruns/ vers GCS (‚ö†Ô∏è IMPORTANT : inclure le run sp√©cifique)
# Utiliser gcloud storage (recommand√© par Google, plus moderne que gsutil)
gcloud storage cp -r mlruns/ gs://$BUCKET_NAME/

# 3. Note: models/metadata.json et models/metrics.json sont inclus dans l'image Docker
#    Ils sont versionn√©s avec Git via DVC et n'ont pas besoin d'√™tre upload√©s s√©par√©ment
#    Le mod√®le est charg√© depuis MLflow via GCS en utilisant mlflow_run_id depuis metadata.json

# 4. V√©rifier
gcloud storage ls gs://$BUCKET_NAME/
gcloud storage ls gs://$BUCKET_NAME/mlruns/
```

### 4. D√©ploiement sur la VM

```bash
# 1. Note: models/metadata.json et models/metrics.json sont inclus dans l'image Docker
#    Ils sont versionn√©s avec Git via DVC et n'ont pas besoin d'√™tre t√©l√©charg√©s
#    Le mod√®le est charg√© depuis MLflow via GCS en utilisant mlflow_run_id depuis metadata.json

# 2. MLFLOW_TRACKING_URI est configur√© automatiquement par Terraform
# (variable d'environnement pass√©e au conteneur Docker)

# 3. L'API charge automatiquement le mod√®le via runs:/<run_id>/model
# MLflow t√©l√©charge temporairement depuis GCS dans son cache (~/.mlflow/cache)
```

**Comment √ßa fonctionne** :
- `metadata.json` contient `mlflow_run_id`
- L'API construit `runs:/<run_id>/model`
- MLflow r√©sout automatiquement vers GCS gr√¢ce √† `MLFLOW_TRACKING_URI`
- Le mod√®le est t√©l√©charg√© temporairement dans le cache MLflow
- Pas besoin de copier manuellement le mod√®le sur la VM

## üîç D√©pannage

### MLflow UI ne d√©marre pas
```bash
# V√©rifier que MLflow est install√©
poetry run mlflow --version

# V√©rifier le port 5000
lsof -i :5000

# Utiliser un autre port
poetry run mlflow ui --port 5001
```

### Configuration MLflow pour d√©veloppement local

**Sans Docker** :
```bash
make train  # MLflow utilise mlruns/ local
```

**Avec Docker Compose** :
```bash
make train           # Entra√Æner sur l'h√¥te
docker compose up    # Conteneur acc√®de √† mlruns/ via volume mont√©
```

**Production avec GCS** :
```bash
# ‚ö†Ô∏è √âTAPE 1 : Cr√©er les ressources GCP d'abord (Terraform)
# terraform apply

# ‚ö†Ô∏è √âTAPE 2 : Uploader mlruns/ vers GCS (apr√®s cr√©ation du bucket)
# Utiliser gcloud storage (recommand√© par Google, plus moderne que gsutil)
BUCKET_NAME=$(terraform -chdir=terraform output -raw bucket_name)
gcloud storage cp -r mlruns/ gs://$BUCKET_NAME/

# ‚ö†Ô∏è √âTAPE 3 : MLFLOW_TRACKING_URI est configur√© automatiquement par Terraform
# L'API chargera automatiquement depuis GCS via run_id dans metadata.json
# MLflow t√©l√©charge temporairement le mod√®le dans son cache (~/.mlflow/cache)
# Format utilis√© : runs:/<run_id>/model (r√©solu automatiquement vers GCS)
```

**Comment √ßa fonctionne** :
- L'API utilise `runs:/<run_id>/model` depuis `metadata.json`
- MLflow r√©sout automatiquement vers GCS gr√¢ce √† `MLFLOW_TRACKING_URI`
- Le mod√®le est t√©l√©charg√© temporairement dans le cache MLflow (`~/.mlflow/cache`)
- Pas besoin de copier manuellement le mod√®le sur la VM

**Alternative : MLflow Tracking Server** :
```bash
# D√©ployer un serveur MLflow (Cloud Run, VM, etc.)
BUCKET_NAME=$(terraform -chdir=terraform output -raw bucket_name)
mlflow server --backend-store-uri gs://$BUCKET_NAME/mlruns/ --default-artifact-root gs://$BUCKET_NAME/mlruns/

# Configurer l'URI
export MLFLOW_TRACKING_URI="http://mlflow-server:5000"
```

### Le mod√®le n'est pas trouv√© dans Docker

```bash
# V√©rifier que le mod√®le existe
ls -la mlruns/

# Red√©marrer le conteneur
docker compose down && docker compose up
```

### DVC pipeline √©choue
```bash
# V√©rifier que les d√©pendances existent
poetry run dvc status

# Nettoyer et r√©ex√©cuter
poetry run dvc repro --force
```

### Donn√©es non trouv√©es
```bash
# V√©rifier que prepare a √©t√© ex√©cut√©
ls -la data/processed/

# R√©ex√©cuter prepare
poetry run dvc repro prepare
```

## ‚úÖ Validation des Objectifs

| Objectif | Status | D√©tails |
|----------|--------|---------|
| **MLflow Tracking** | ‚úÖ | Int√©gration compl√®te avec logging param√®tres/m√©triques |
| **MLflow UI** | ‚úÖ | Interface web fonctionnelle |
| **DVC Pipeline** | ‚úÖ | Pipeline √† 2 √©tapes (prepare, train) |
| **Versioning Donn√©es** | ‚úÖ | Dataset versionn√© avec DVC |
| **Reproductibilit√©** | ‚úÖ | Pipeline reproductible |
| **Documentation** | ‚úÖ | Guide complet dans ce fichier |

---

**üéâ Phase 4 termin√©e avec succ√®s !**

Le projet dispose maintenant de :
- ‚úÖ Tracking complet des exp√©riences ML avec MLflow
- ‚úÖ Versioning des donn√©es et pipeline reproductible avec DVC
- ‚úÖ Documentation compl√®te et guide d'utilisation

Le Projet 1 est maintenant finalis√© et pr√™t pour la d√©monstration !
