# üü£ Phase 5 : Orchestration - Kubernetes avec Auto-Scaling

## üß≠ Navigation

| ‚Üê Pr√©c√©dent | Suivant ‚Üí |
|-------------|-----------|
| [Phase 4 : Exp√©rimentation](PHASE_4.md) | Phase 6 : Observabilit√© (√† venir) |
| [Retour au README](../README.md) | [Toutes les phases](.) |

## üìã Table des Mati√®res

1. [Objectif de la Phase](#-objectif-de-la-phase)
2. [T√¢ches √† Accomplir](#-t√¢ches-√†-accomplir)
3. [Livrables Cr√©√©s](#-livrables-cr√©√©s)
4. [Fonctionnalit√©s Impl√©ment√©es](#-fonctionnalit√©s-impl√©ment√©es)
5. [Concepts Kubernetes](#-concepts-kubernetes)
6. [Architecture du D√©ploiement](#-architecture-du-d√©ploiement)
7. [Installation et Configuration](#-installation-et-configuration)
8. [Guide de D√©ploiement](#-guide-de-d√©ploiement)
9. [Workflows MLflow](#-workflows-mlflow)
10. [Auto-Scaling avec HPA](#-auto-scaling-avec-hpa)
11. [Tests et Validation](#-tests-et-validation)
12. [Commandes Utiles](#-commandes-utiles)
13. [S√©curit√©](#-s√©curit√©)
14. [D√©pannage](#-d√©pannage)
15. [M√©triques](#-m√©triques)
16. [Validation des Objectifs](#-validation-des-objectifs)
17. [Prochaines √âtapes](#-prochaines-√©tapes-phase-6)
18. [Ressources](#-ressources)

---

## üéØ Objectif de la Phase

**Orchestrer l'application ML containeris√©e sur Kubernetes avec haute disponibilit√© et auto-scaling**

### ‚ùì Questions Cl√©s
- Qu'est-ce qu'un Pod, un Deployment et un Service dans Kubernetes ?
- Comment exposer une application dockeris√©e dans un cluster K8s ?
- Comment g√©rer les configurations et secrets dans Kubernetes ?
- Comment mettre en place le scaling automatique bas√© sur les m√©triques ?

### ‚è±Ô∏è R√©partition des Heures (20h)
- **8h** ‚Üí Apprentissage des concepts K8s (Pods, Deployments, Services, ConfigMaps, Secrets)
- **8h** ‚Üí Installation et utilisation de minikube/kind localement
- **4h** ‚Üí D√©ploiement de l'API ML dockeris√©e sur le cluster local K8s

---

## üìã T√¢ches √† Accomplir

### 1. üéì Apprendre les Concepts Kubernetes
- Comprendre l'architecture d'un cluster Kubernetes
- Ma√Ætriser les concepts de base : Pods, Deployments, Services
- G√©rer les configurations avec ConfigMaps et Secrets
- Comprendre les Namespaces pour l'isolation

### 2. üõ†Ô∏è Installation et Configuration
- Installer kubectl (client Kubernetes)
- Configurer un cluster local (minikube ou kind)
- V√©rifier la connectivit√© au cluster

### 3. üöÄ D√©ploiement de l'Application
- Cr√©er les manifests Kubernetes (Deployment, Service, ConfigMap, Secret)
- D√©ployer l'API FastAPI sur le cluster
- Configurer les health checks (liveness et readiness probes)
- Exposer l'API via Service et Ingress

### 4. üìä Int√©gration MLflow
- D√©ployer un serveur MLflow dans le cluster
- Configurer le partage de volumes pour les donn√©es MLflow
- Connecter l'API au serveur MLflow

### 5. ‚öñÔ∏è Auto-Scaling
- Configurer le Horizontal Pod Autoscaler (HPA)
- D√©finir les m√©triques de scaling (CPU, m√©moire)
- Tester le scaling automatique

---

## üì¶ Livrables Cr√©√©s

### Structure des Fichiers Kubernetes

```
k8s/
‚îú‚îÄ‚îÄ namespace.yaml              # Namespace mlops pour isolation
‚îú‚îÄ‚îÄ deployment.yaml             # Deployment API (2 replicas)
‚îú‚îÄ‚îÄ mlflow-deployment.yaml      # Deployment MLflow server (1 replica)
‚îú‚îÄ‚îÄ service.yaml                # Service ClusterIP pour l'API
‚îú‚îÄ‚îÄ mlflow-service.yaml         # Service ClusterIP pour MLflow
‚îú‚îÄ‚îÄ service-nodeport.yaml       # Service NodePort (dev/test)
‚îú‚îÄ‚îÄ configmap.yaml              # Configuration non sensible
‚îú‚îÄ‚îÄ secret.yaml.example         # Template pour secrets
‚îú‚îÄ‚îÄ ingress.yaml                # Ingress pour exposition externe
‚îú‚îÄ‚îÄ hpa.yaml                    # Horizontal Pod Autoscaler
‚îî‚îÄ‚îÄ README.md                   # Guide rapide de d√©ploiement
```

### Fichiers Principaux

#### `k8s/deployment.yaml` - D√©ploiement de l'API
- **Replicas** : 2 pods pour haute disponibilit√©
- **Strategy** : RollingUpdate (zero-downtime)
- **Health Checks** : Liveness et readiness probes sur `/health`
- **Ressources** : Requests et limits CPU/m√©moire
- **S√©curit√©** : Containers non-root, capabilities limit√©es
- **Volumes** : Partage de `mlruns/` via hostPath

#### `k8s/mlflow-deployment.yaml` - Serveur MLflow
- **Replicas** : 1 (singleton)
- **Strategy** : Recreate (serveur avec √©tat)
- **Image** : `ghcr.io/mlflow/mlflow:v2.9.2`
- **Backend Store** : Fichier local (`file:///mlruns`)
- **Volume** : Partage du m√™me volume que l'API

#### `k8s/service.yaml` - Service ClusterIP
- **Type** : ClusterIP (acc√®s interne uniquement)
- **Port** : 8000
- **Selector** : `app: iris-api`
- **Load Balancing** : Round-robin entre les pods

#### `k8s/configmap.yaml` - Configuration
- Variables d'environnement non sensibles :
  - `ENVIRONMENT`: production
  - `MODEL_DIR`: /app/models
  - `LOG_LEVEL`: INFO

#### `k8s/secret.yaml.example` - Template Secrets
- `API_KEY`: Cl√© API pour authentification
- `MLFLOW_TRACKING_URI`: URI du serveur MLflow ou GCS

#### `k8s/hpa.yaml` - Auto-Scaling
- **Min replicas** : 2
- **Max replicas** : 10
- **M√©triques** : CPU (70%) et m√©moire (80%)
- **Comportement** : Scaling up r√©actif, scaling down prudent

#### `k8s/ingress.yaml` - Exposition Externe
- **Controller** : nginx-ingress
- **TLS** : Support HTTPS (cert-manager)
- **Annotations** : Rate limiting, CORS, timeouts

---

## ‚úÖ Fonctionnalit√©s Impl√©ment√©es

### D√©ploiement Kubernetes
- ‚úÖ Namespace `mlops` pour isolation
- ‚úÖ Deployment avec 2 replicas pour haute disponibilit√©
- ‚úÖ Rolling update sans interruption de service
- ‚úÖ Health checks (liveness et readiness probes)
- ‚úÖ Gestion des ressources (requests et limits)
- ‚úÖ S√©curit√© renforc√©e (non-root, capabilities limit√©es)

### Services et Exposition
- ‚úÖ Service ClusterIP pour acc√®s interne
- ‚úÖ Service NodePort pour d√©veloppement/test
- ‚úÖ Ingress pour exposition externe avec TLS
- ‚úÖ Load balancing automatique entre pods

### Configuration et Secrets
- ‚úÖ ConfigMap pour variables d'environnement non sensibles
- ‚úÖ Secrets Kubernetes pour donn√©es sensibles (API keys)
- ‚úÖ Injection via `envFrom` et `env`
- ‚úÖ Template de secret avec instructions

### MLflow Integration
- ‚úÖ Serveur MLflow d√©ploy√© dans le cluster
- ‚úÖ Partage de volumes entre API et MLflow
- ‚úÖ Service ClusterIP pour acc√®s interne
- ‚úÖ Support de trois modes :
  - Serveur MLflow dans K8s (recommand√©)
  - Local avec hostPath (d√©veloppement)
  - GCS (production cloud)

### Auto-Scaling
- ‚úÖ Horizontal Pod Autoscaler (HPA) configur√©
- ‚úÖ Scaling bas√© sur CPU et m√©moire
- ‚úÖ Comportement configurable (stabilisation, politiques)
- ‚úÖ M√©triques via metrics-server

### Commandes Makefile
- ‚úÖ `make k8s-setup` : Installation minikube/kind
- ‚úÖ `make k8s-deploy` : D√©ploiement API
- ‚úÖ `make k8s-deploy-mlflow` : D√©ploiement API + MLflow
- ‚úÖ `make k8s-status` : V√©rification du statut
- ‚úÖ `make k8s-logs` : Visualisation des logs
- ‚úÖ `make k8s-port-forward` : Acc√®s √† l'API
- ‚úÖ `make k8s-mlflow-ui` : Acc√®s √† MLflow UI
- ‚úÖ `make k8s-test` : Tests automatis√©s
- ‚úÖ `make k8s-clean` : Nettoyage complet

---

## üéì Concepts Kubernetes

### Pod
**Plus petite unit√© d√©ployable** dans Kubernetes. Contient un ou plusieurs containers qui partagent :
- Le m√™me r√©seau (m√™me IP)
- Le m√™me stockage (volumes)
- Le m√™me namespace

**Exemple** : Un Pod contient l'API FastAPI.

### Deployment
**Orchestrateur qui g√®re un ensemble de Pods identiques** (replicas). Assure :
- ‚úÖ Cr√©ation et mise √† jour des Pods
- ‚úÖ Rolling update (d√©ploiement sans interruption)
- ‚úÖ Rollback en cas de probl√®me
- ‚úÖ Scaling (augmentation/r√©duction)

**Dans notre cas** : 2 Pods identiques pour la haute disponibilit√©.

### Service
**Expose un ensemble de Pods comme un service r√©seau**. Fournit :
- ‚úÖ IP stable (ClusterIP)
- ‚úÖ √âquilibrage de charge entre les Pods
- ‚úÖ DNS interne (`service-name.namespace.svc.cluster.local`)

**Types** :
- **ClusterIP** : Acc√®s interne uniquement
- **NodePort** : Acc√®s externe via port sur chaque node
- **LoadBalancer** : IP publique externe (cloud)
- **Ingress** : Routage HTTP/HTTPS bas√© sur domaine

### ConfigMap
**Stocke des donn√©es de configuration non sensibles** (cl√©-valeur).

**Dans notre cas** : `ENVIRONMENT`, `MODEL_DIR`, `LOG_LEVEL`.

### Secret
**Stocke des donn√©es sensibles** (cl√©s API, mots de passe). Similaire √† ConfigMap mais :
- ‚úÖ Encod√© en base64
- ‚úÖ Plus s√©curis√© (ne pas exposer dans les logs)

**Dans notre cas** : `API_KEY`, `MLFLOW_TRACKING_URI`.

### Namespace
**Isole des ressources dans un cluster**. Utile pour :
- ‚úÖ S√©parer les environnements (dev, staging, prod)
- ‚úÖ Limiter les permissions (RBAC)
- ‚úÖ Organiser les ressources

**Dans notre cas** : Namespace `mlops` pour toutes les ressources.

### Volume
**Permet aux pods de partager des donn√©es**. Types :
- **hostPath** : Monte un r√©pertoire de la machine h√¥te
- **PersistentVolume** : Stockage persistant
- **ConfigMap/Secret** : Mont√©s comme volumes

**Dans notre cas** : `hostPath` pour partager `mlruns/` entre pods.

### HPA (Horizontal Pod Autoscaler)
**Ajuste automatiquement le nombre de replicas** selon les m√©triques (CPU, m√©moire).

**Dans notre cas** : Scale entre 2 et 10 pods selon CPU (70%) et m√©moire (80%).

---

## üèóÔ∏è Architecture du D√©ploiement

### Vue d'Ensemble

Le cluster Kubernetes h√©berge **3 applications principales** r√©parties dans **2 namespaces** :

| Application | Namespace | R√¥le |
|-------------|-----------|------|
| **nginx** (Ingress Controller) | `ingress-nginx` | Reverse proxy, routage HTTP/HTTPS |
| **iris-api** (FastAPI) | `mlops` | API ML pour pr√©dictions |
| **mlflow-server** (MLflow) | `mlops` | Tracking et gestion des mod√®les ML |

### Namespaces

#### Namespace `ingress-nginx`

**R√¥le** : H√©berge l'Ingress Controller nginx (optionnel, pour exposition externe)

**Ressources** :
- Deployment `ingress-nginx-controller`
- Service `ingress-nginx-controller` (LoadBalancer ou NodePort)
- ConfigMaps, Secrets pour la configuration nginx

**Installation** :
```bash
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/cloud/deploy.yaml
```

**V√©rification** :
```bash
kubectl get pods -n ingress-nginx
kubectl get service -n ingress-nginx
```

#### Namespace `mlops`

**R√¥le** : H√©berge les applications m√©tier (API et MLflow)

**Ressources** :
- Deployment `iris-api` (2 replicas)
- Deployment `mlflow-server` (1 replica)
- Services `iris-api-service` et `mlflow-server-service`
- ConfigMap `iris-api-config`
- Secret `iris-api-secrets`
- Ingress `iris-api-ingress` (optionnel)
- HPA `iris-api-hpa` (optionnel)

**Cr√©ation** :
```bash
kubectl apply -f k8s/namespace.yaml
```

**V√©rification** :
```bash
kubectl get all -n mlops
```

### Applications et Pods

#### 1. Nginx Ingress Controller (Optionnel)

**Namespace** : `ingress-nginx` (ou `kube-system`)

**Deployment** : `ingress-nginx-controller`

**Container** :
- **Image** : `registry.k8s.io/ingress-nginx/controller`
- **Application** : nginx (reverse proxy)
- **Ports** : 80 (HTTP), 443 (HTTPS)

**R√¥le** :
- ‚úÖ Lit les r√®gles Ingress de tous les namespaces
- ‚úÖ Route le trafic HTTP/HTTPS vers les Services appropri√©s
- ‚úÖ G√®re TLS/HTTPS (terminaison SSL)
- ‚úÖ Rate limiting (protection DDoS)
- ‚úÖ CORS (Cross-Origin Resource Sharing)
- ‚úÖ Load balancing au niveau HTTP

**Service** :
- **Type** : `LoadBalancer` (production cloud) ou `NodePort` (local)
- **Acc√®s** : Production via IP publique du LoadBalancer, Local via `http://<node-ip>:<nodePort>`

#### 2. Iris API (FastAPI)

**Namespace** : `mlops`

**Deployment** : `iris-api`

**Pods** : `iris-api-<hash>-1`, `iris-api-<hash>-2` (2 replicas)

**Container** :
- **Image** : `iris-api:latest` (ou depuis Artifact Registry)
- **Application** : FastAPI (serveur web Python)
- **Port** : 8000

**R√¥le** :
- ‚úÖ API REST pour pr√©dictions ML
- ‚úÖ Endpoints : `/predict`, `/health`, `/metrics`
- ‚úÖ Authentification via API Key
- ‚úÖ Charge les mod√®les depuis MLflow
- ‚úÖ M√©triques Prometheus

**Service** :
- **Type** : `ClusterIP` (acc√®s interne uniquement)
- **DNS** : `iris-api-service.mlops.svc.cluster.local`
- **Port** : 8000

**Acc√®s** :
- Depuis nginx : `http://iris-api-service:8000`
- Depuis mlflow-server : `http://iris-api-service:8000`
- Depuis l'ext√©rieur : Via port-forward ou Ingress

#### 3. MLflow Server

**Namespace** : `mlops`

**Deployment** : `mlflow-server`

**Pod** : `mlflow-server-<hash>` (1 replica)

**Container** :
- **Image** : `ghcr.io/mlflow/mlflow:v2.9.2`
- **Application** : MLflow (serveur de tracking ML)
- **Port** : 5000

**R√¥le** :
- ‚úÖ Stocke les runs ML (exp√©riences, param√®tres, m√©triques)
- ‚úÖ Sert les mod√®les ML (artifacts)
- ‚úÖ UI MLflow (interface web)
- ‚úÖ API REST MLflow

**Service** :
- **Type** : `ClusterIP` (acc√®s interne uniquement)
- **DNS** : `mlflow-server-service.mlops.svc.cluster.local`
- **Port** : 5000

**Acc√®s** :
- Depuis iris-api : `http://mlflow-server-service:5000`
- Depuis l'ext√©rieur : Via port-forward (`make k8s-mlflow-ui`)

### Services

#### Service iris-api

**Namespace** : `mlops`

**Nom** : `iris-api-service`

**Type** : `ClusterIP` (interne uniquement)

**Port** : 8000 ‚Üí 8000

**S√©lecteur** : `app: iris-api`

**DNS** : `iris-api-service.mlops.svc.cluster.local`

**R√¥le** :
- ‚úÖ Load balancing entre les 2 pods iris-api
- ‚úÖ DNS stable (m√™me si les pods red√©marrent)
- ‚úÖ Point d'acc√®s unique pour nginx

**Acc√®s depuis nginx** :
```yaml
# Dans ingress.yaml
backend:
  service:
    name: iris-api-service  # Service dans namespace mlops
    port:
      number: 8000
```

#### Service mlflow-server

**Namespace** : `mlops`

**Nom** : `mlflow-server-service`

**Type** : `ClusterIP` (interne uniquement)

**Port** : 5000 ‚Üí 5000

**S√©lecteur** : `app: mlflow-server`

**DNS** : `mlflow-server-service.mlops.svc.cluster.local`

**R√¥le** :
- ‚úÖ Point d'acc√®s stable pour mlflow-server
- ‚úÖ Utilis√© par iris-api pour charger les mod√®les

**Acc√®s depuis iris-api** :
```python
# Dans le code Python
MLFLOW_TRACKING_URI = "http://mlflow-server-service:5000"
```

### Communication Inter-Namespace

Kubernetes permet la communication entre namespaces via le DNS interne.

#### Format DNS Kubernetes

```
<service-name>.<namespace>.svc.cluster.local
```

#### Exemples dans l'Architecture

**1. Nginx ‚Üí Iris API** :
```yaml
# Dans ingress.yaml (namespace: mlops)
# Nginx (namespace: ingress-nginx) lit cette r√®gle
backend:
  service:
    name: iris-api-service  # Service dans namespace mlops
    port:
      number: 8000
```

**DNS utilis√©** : `iris-api-service.mlops.svc.cluster.local:8000`

**2. Iris API ‚Üí MLflow Server** :
```python
# Dans secret.yaml (namespace: mlops)
MLFLOW_TRACKING_URI: "http://mlflow-server-service:5000"
# ou explicitement :
# MLFLOW_TRACKING_URI: "http://mlflow-server-service.mlops.svc.cluster.local:5000"
```

**DNS utilis√©** : `mlflow-server-service.mlops.svc.cluster.local:5000`

#### Raccourci DNS

Dans le m√™me namespace, vous pouvez utiliser juste le nom du service :

```python
# Dans namespace mlops
MLFLOW_TRACKING_URI: "http://mlflow-server-service:5000"
# √âquivalent √† :
# MLFLOW_TRACKING_URI: "http://mlflow-server-service.mlops.svc.cluster.local:5000"
```

### Volumes Partag√©s

#### Volume `mlruns-volume`

**Type** : `hostPath`

**Path sur le n≈ìud** : `/tmp/mlruns`

**Mont√© dans** :

**1. Pods iris-api** :
```yaml
volumeMounts:
- name: mlruns-volume
  mountPath: /app/mlruns  # O√π le code Python cherche mlruns/
  readOnly: false
```

**Usage** :
- ‚úÖ N√©cessaire si `MLFLOW_TRACKING_URI=""` (mode local)
- ‚ùå Pas n√©cessaire si `MLFLOW_TRACKING_URI="http://mlflow-server-service:5000"` (mode serveur)

**2. Pod mlflow-server** :
```yaml
volumeMounts:
- name: mlruns-volume
  mountPath: /mlruns  # MLflow stocke tout ici
  readOnly: false
```

**Usage** :
- ‚úÖ Toujours n√©cessaire (mlflow-server stocke les donn√©es ici)

#### Partage de Donn√©es

**Workflow avec MLflow Server** :
1. MLflow server stocke dans `/mlruns` (volume partag√©)
2. Iris-api charge via HTTP : `http://mlflow-server-service:5000`
3. Le volume n'est pas utilis√© par iris-api (mais n√©cessaire pour mlflow-server)

**Workflow Local** :
1. Mod√®le dans `/app/mlruns` (volume partag√©)
2. Iris-api charge directement depuis le syst√®me de fichiers
3. Le volume est utilis√© par iris-api

### Flux de Trafic

#### Flux 1 : Client ‚Üí API (via Ingress)

**√âtapes** :
1. Client Internet envoie une requ√™te HTTP/HTTPS vers `iris-api.example.com`
2. DNS r√©sout vers l'IP du LoadBalancer (nginx)
3. Service `ingress-nginx-controller` route vers le Pod nginx (namespace: `ingress-nginx`)
4. Nginx lit les r√®gles Ingress (cherche dans TOUS les namespaces)
5. Nginx trouve l'Ingress `iris-api-ingress` (namespace: `mlops`)
6. Nginx route vers le Service `iris-api-service` (namespace: `mlops`)
7. Service load balance vers un Pod iris-api (1 ou 2)
8. FastAPI traite la requ√™te et retourne la r√©ponse

#### Flux 2 : API ‚Üí MLflow Server (interne)

**√âtapes** :
1. Pod iris-api envoie une requ√™te HTTP vers `http://mlflow-server-service:5000`
2. Service `mlflow-server-service` route vers le Pod mlflow-server
3. MLflow traite la requ√™te et retourne le mod√®le ou les m√©tadonn√©es
4. Pod iris-api charge le mod√®le et l'utilise pour les pr√©dictions

#### Flux 3 : Port-Forward (d√©veloppement)

**√âtapes** :
1. Votre machine locale utilise `kubectl port-forward`
2. Le port-forward se connecte directement au Service `iris-api-service`
3. Service load balance vers un Pod iris-api (1 ou 2)
4. FastAPI traite la requ√™te et retourne la r√©ponse sur `localhost:8000`

**Note** : Le port-forward contourne compl√®tement nginx et l'Ingress.

### Modes MLflow

| Mode | MLFLOW_TRACKING_URI | Volume | Usage |
|------|---------------------|--------|-------|
| **K8s Server** | `http://mlflow-server-service:5000` | Partag√© | Portfolio/Production |
| **Local** | `""` | hostPath + mount | D√©veloppement |
| **GCS** | `gs://bucket/mlruns/` | Aucun | Production cloud |

### Tableau R√©capitulatif

| Composant | Namespace | Type | Nom | Port | Acc√®s |
|-----------|-----------|------|-----|------|-------|
| **nginx** | `ingress-nginx` | Deployment | `ingress-nginx-controller` | 80, 443 | Internet (LoadBalancer) |
| **iris-api** | `mlops` | Deployment | `iris-api` | 8000 | Interne (ClusterIP) |
| **mlflow-server** | `mlops` | Deployment | `mlflow-server` | 5000 | Interne (ClusterIP) |
| **Ingress** | `mlops` | Ingress | `iris-api-ingress` | - | R√®gles de routage |
| **Volume** | `mlops` | Volume | `mlruns-volume` | - | Partag√© entre pods |

---

## üöÄ Installation et Configuration

### Pr√©requis

| Outil | Version | Description |
|-------|---------|-------------|
| **kubectl** | >= 1.28 | Client Kubernetes |
| **Docker** | >= 20.10 | Pour minikube/kind |
| **minikube** | >= 1.30 | Ou **kind** >= 0.20 | Cluster local |

### Installation Automatique (Recommand√©)

```bash
# Avec minikube
make k8s-setup

# Avec kind
make k8s-setup-kind

# Ou directement
./scripts/setup-k8s.sh minikube
./scripts/setup-k8s.sh kind
```

### Installation Manuelle

#### 1. Installer kubectl

**macOS** :
```bash
brew install kubectl
```

**Linux** :
```bash
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
```

#### 2. Installer minikube ou kind

**minikube** (macOS) :
```bash
brew install minikube
minikube start --driver=docker --memory=4096 --cpus=2
```

**kind** :
```bash
brew install kind  # macOS
kind create cluster --name mlops-cluster
```

#### 3. V√©rifier

```bash
kubectl cluster-info
kubectl get nodes
```

---

## üöÄ Guide de D√©ploiement

### √âtape 1 : Pr√©parer l'Image Docker

**Option A : Image Locale (minikube)**
```bash
eval $(minikube docker-env)
make build
```

**Option B : Artifact Registry (Production)**
```yaml
# Dans k8s/deployment.yaml
image: europe-west1-docker.pkg.dev/PROJECT_ID/mlops-repo/iris-api:latest
imagePullPolicy: Always
```

### √âtape 2 : Pr√©parer les Secrets

```bash
cp k8s/secret.yaml.example k8s/secret.yaml
# √âditer k8s/secret.yaml avec vos valeurs
# ‚ö†Ô∏è Ne JAMAIS commiter secret.yaml !
```

**Contenu de `k8s/secret.yaml`** :
```yaml
apiVersion: v1
kind: Secret
metadata:
  name: iris-api-secrets
  namespace: mlops
type: Opaque
stringData:
  API_KEY: "votre-api-key-ici"  # openssl rand -hex 32
  MLFLOW_TRACKING_URI: "http://mlflow-server-service:5000"  # Ou "gs://bucket/mlruns/"
```

### √âtape 3 : D√©ployer

**Option A : Avec MLflow Server** (Recommand√©)
```bash
make k8s-deploy-mlflow
```

**Option B : MLflow Local**
```bash
# 1. Monter mlruns/ (terminal s√©par√©)
minikube mount $(pwd)/mlruns:/tmp/mlruns

# 2. D√©ployer
make k8s-deploy
```

**Manuellement** :
```bash
kubectl apply -f k8s/namespace.yaml
kubectl apply -f k8s/configmap.yaml
kubectl apply -f k8s/secret.yaml
kubectl apply -f k8s/mlflow-deployment.yaml  # Si MLflow server
kubectl apply -f k8s/mlflow-service.yaml
kubectl apply -f k8s/deployment.yaml
kubectl apply -f k8s/service.yaml
```

### √âtape 4 : V√©rifier

```bash
make k8s-status
# ou
kubectl get pods,services -n mlops
```

**R√©sultat attendu** :
```
NAME                        READY   STATUS    RESTARTS   AGE
iris-api-xxxxxxxxxx-xxxxx   1/1     Running   0          30s
iris-api-xxxxxxxxxx-xxxxx   1/1     Running   0          30s
mlflow-server-xxxxx         1/1     Running   0          30s
```

### √âtape 5 : Acc√©der √† l'API

**Port-Forward** (D√©veloppement) :
```bash
make k8s-port-forward
# http://localhost:8000
```

**MLflow UI** (si d√©ploy√©) :
```bash
make k8s-mlflow-ui
# http://localhost:5000
```

**NodePort** (Test) :
```bash
kubectl apply -f k8s/service-nodeport.yaml
NODE_IP=$(kubectl get nodes -o jsonpath='{.items[0].status.addresses[?(@.type=="InternalIP")].address}')
curl http://$NODE_IP:30080/health
```

**Ingress** (Production) :
```bash
# Installer Ingress Controller
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/cloud/deploy.yaml
kubectl apply -f k8s/ingress.yaml
```

---

## üîÑ Workflows MLflow

### Workflow 1 : Migration des Donn√©es Existantes

**Objectif** : Utiliser un mod√®le d√©j√† entra√Æn√© localement

```bash
# 1. Monter mlruns/ local vers le cluster
minikube mount $(pwd)/mlruns:/tmp/mlruns

# 2. D√©ployer (MLFLOW_TRACKING_URI="")
make k8s-deploy

# 3. V√©rifier
kubectl exec -it deployment/iris-api -n mlops -- ls -la /app/mlruns
```

### Workflow 2 : R√©entra√Ænement vers MLflow Server

**Objectif** : Entra√Æner un nouveau mod√®le vers le serveur MLflow

```bash
# 1. D√©ployer MLflow server
kubectl apply -f k8s/namespace.yaml
kubectl apply -f k8s/mlflow-deployment.yaml
kubectl apply -f k8s/mlflow-service.yaml

# 2. Port-forward (terminal s√©par√©)
kubectl port-forward service/mlflow-server-service 5000:5000 -n mlops

# 3. Entra√Æner vers le serveur
export MLFLOW_TRACKING_URI="http://localhost:5000"
make train

# 4. D√©ployer l'API
kubectl apply -f k8s/configmap.yaml
kubectl apply -f k8s/secret.yaml  # MLFLOW_TRACKING_URI="http://mlflow-server-service:5000"
kubectl apply -f k8s/deployment.yaml
kubectl apply -f k8s/service.yaml
```

### Workflow 3 : Production avec GCS

**Objectif** : Utiliser GCS comme backend MLflow (production cloud)

```bash
# 1. Configurer secret.yaml
# MLFLOW_TRACKING_URI: "gs://bucket-name/mlruns/"

# 2. D√©ployer (pas besoin de volume hostPath)
kubectl apply -f k8s/deployment.yaml

# 3. L'API charge automatiquement depuis GCS
```

---

## üìä Auto-Scaling avec HPA

### Installation de metrics-server

```bash
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
```

### D√©ploiement du HPA

```bash
kubectl apply -f k8s/hpa.yaml
```

### V√©rification

```bash
kubectl get hpa -n mlops
kubectl describe hpa iris-api-hpa -n mlops
```

### Test du Scaling

```bash
# G√©n√©rer de la charge
while true; do curl http://localhost:8000/health; done

# Observer le scaling
watch kubectl get pods -n mlops
kubectl get hpa -n mlops
```

Le HPA scale automatiquement entre 2 et 10 pods selon CPU (70%) et m√©moire (80%).

---

## üß™ Tests et Validation

### Test 1 : Health Check

```bash
make k8s-port-forward  # Terminal 1
curl http://localhost:8000/health  # Terminal 2
```

**R√©sultat attendu** :
```json
{
  "status": "healthy",
  "model_loaded": true,
  "version": "1.0.0"
}
```

### Test 2 : Pr√©diction

```bash
export API_KEY=$(kubectl get secret iris-api-secrets -n mlops -o jsonpath='{.data.API_KEY}' | base64 -d)

curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -H "X-API-Key: $API_KEY" \
  -d '{
    "sepal_length": 5.1,
    "sepal_width": 3.5,
    "petal_length": 1.4,
    "petal_width": 0.2
  }'
```

### Test 3 : Logs

```bash
make k8s-logs
# ou
kubectl logs -f deployment/iris-api -n mlops
```

### Test 4 : Scaling Manuel

```bash
kubectl scale deployment iris-api --replicas=3 -n mlops
kubectl get pods -n mlops
```

### Test 5 : Auto-Scaling (HPA)

```bash
# Installer metrics-server
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

# D√©ployer HPA
kubectl apply -f k8s/hpa.yaml

# G√©n√©rer de la charge
while true; do curl http://localhost:8000/health; done

# Observer le scaling
watch kubectl get pods -n mlops
```

---

## üìù Commandes Utiles

### Commandes Makefile

| Commande | Description |
|----------|-------------|
| `make k8s-setup` | Installer minikube et cr√©er le cluster |
| `make k8s-setup-kind` | Installer kind et cr√©er le cluster |
| `make k8s-deploy` | D√©ployer l'API |
| `make k8s-deploy-mlflow` | D√©ployer API + MLflow server |
| `make k8s-status` | V√©rifier le statut |
| `make k8s-logs` | Voir les logs |
| `make k8s-port-forward` | Port-forward vers l'API |
| `make k8s-mlflow-ui` | Port-forward vers MLflow UI |
| `make k8s-test` | Tester l'API |
| `make k8s-clean` | Nettoyer compl√®tement |

### Commandes kubectl Essentielles

```bash
# Voir toutes les ressources
kubectl get all -n mlops

# D√©crire un pod
kubectl describe pod <pod-name> -n mlops

# Ex√©cuter une commande dans un pod
kubectl exec -it <pod-name> -n mlops -- /bin/bash

# Voir les √©v√©nements
kubectl get events -n mlops --sort-by='.lastTimestamp'

# Red√©marrer le d√©ploiement
kubectl rollout restart deployment/iris-api -n mlops

# Rollback
kubectl rollout undo deployment/iris-api -n mlops

# Voir les ressources utilis√©es
kubectl top pods -n mlops
```

---

## üîí S√©curit√©

### Bonnes Pratiques Impl√©ment√©es

- ‚úÖ **Secrets Kubernetes** : Jamais en clair dans Git
- ‚úÖ **Containers non-root** : `runAsNonRoot: true`, `runAsUser: 1000`
- ‚úÖ **Capabilities limit√©es** : `drop: [ALL]`
- ‚úÖ **Read-only root filesystem** : Optionnel (d√©sactiv√© pour logs)
- ‚úÖ **Seccomp profile** : `RuntimeDefault`
- ‚úÖ **TLS via Ingress** : Support HTTPS en production
- ‚úÖ **RBAC** : Permissions limit√©es par namespace

### Recommandations Production

- üîê Utiliser External Secrets Operator avec Secret Manager GCP/AWS
- üîê Activer Network Policies pour isolation r√©seau
- üîê Configurer Pod Security Standards
- üîê Utiliser cert-manager pour TLS automatique
- üîê Activer audit logging
- üîê Scanner les images pour vuln√©rabilit√©s (Trivy, Snyk)

---

## üîç D√©pannage

### Pods ne d√©marrent pas

**Sympt√¥mes** : `Pending` ou `CrashLoopBackOff`

**Solutions** :
```bash
kubectl describe pod <pod-name> -n mlops
kubectl logs <pod-name> -n mlops
kubectl get events -n mlops --sort-by='.lastTimestamp'

# Causes courantes :
# - Image non trouv√©e : V√©rifier deployment.yaml
# - Secrets manquants : V√©rifier secret.yaml
# - Ressources insuffisantes : V√©rifier le cluster
```

### API ne r√©pond pas

**Solutions** :
```bash
kubectl get pods -n mlops
kubectl logs -f deployment/iris-api -n mlops
kubectl get service iris-api-service -n mlops

# Tester depuis un pod
kubectl run -it --rm debug --image=curlimages/curl --restart=Never -- curl http://iris-api-service:8000/health
```

### Secrets non trouv√©s

**Solutions** :
```bash
kubectl get secret iris-api-secrets -n mlops
kubectl describe secret iris-api-secrets -n mlops

# Recr√©er si n√©cessaire
kubectl delete secret iris-api-secrets -n mlops
kubectl apply -f k8s/secret.yaml
```

### Image non trouv√©e

**Avec minikube** :
```bash
eval $(minikube docker-env)
docker build -t iris-api:latest .
```

**Avec Artifact Registry** :
```bash
gcloud auth configure-docker europe-west1-docker.pkg.dev
# Modifier deployment.yaml avec l'image compl√®te
```

### HPA ne fonctionne pas

**Solutions** :
```bash
# V√©rifier metrics-server
kubectl get deployment metrics-server -n kube-system

# Installer si n√©cessaire
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

# V√©rifier les m√©triques
kubectl top pods -n mlops
kubectl describe hpa iris-api-hpa -n mlops
```

---

## üìä M√©triques

| M√©trique | Valeur |
|----------|--------|
| **Fichiers cr√©√©s** | 10+ manifests Kubernetes |
| **Pods d√©ploy√©s** | 2 (API) + 1 (MLflow) |
| **Services** | 2 (ClusterIP) |
| **Auto-scaling** | 2-10 pods selon charge |
| **Health checks** | Liveness + Readiness |
| **Commandes Make** | 10+ commandes k8s-* |

---

## ‚úÖ Validation des Objectifs

| Objectif | Status | D√©tails |
|----------|--------|---------|
| **Concepts K8s** | ‚úÖ | Compris : Pods, Deployments, Services, ConfigMaps, Secrets |
| **Installation** | ‚úÖ | minikube/kind install√© et cluster cr√©√© |
| **Manifests** | ‚úÖ | Tous les manifests cr√©√©s |
| **D√©ploiement** | ‚úÖ | API d√©ploy√©e sur le cluster local |
| **Health Checks** | ‚úÖ | Liveness et readiness probes configur√©s |
| **MLflow Integration** | ‚úÖ | Serveur MLflow d√©ploy√© et connect√© |
| **Auto-Scaling** | ‚úÖ | HPA configur√© et fonctionnel |
| **Tests** | ‚úÖ | API accessible et fonctionnelle |
| **Documentation** | ‚úÖ | Guide complet avec exemples |

---

## üöÄ Prochaines √âtapes (Phase 6)

- üìä Observabilit√© & Monitoring (Prometheus, Grafana)
- üîç M√©triques avanc√©es
- üìà Dashboards de monitoring
- üö® Alertes et notifications
- üìù Logging structur√© et centralis√©

---

## üìö Ressources

### Documentation

- [Guide Kubernetes](../k8s/README.md) - Guide rapide de d√©ploiement
- [Kubernetes Documentation](https://kubernetes.io/docs/) - Documentation officielle
- [minikube](https://minikube.sigs.k8s.io/) - Cluster local
- [kind](https://kind.sigs.k8s.io/) - Kubernetes in Docker

### Ressources Externes

- [Kubernetes Concepts](https://kubernetes.io/docs/concepts/)
- [Kubernetes Best Practices](https://kubernetes.io/docs/concepts/configuration/overview/)
- [MLflow Kubernetes](https://mlflow.org/docs/latest/tracking.html#scenario-5-mlflow-on-kubernetes)
- [HPA Documentation](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/)

---

**üéâ Phase 5 termin√©e avec succ√®s !**

L'API MLOps est maintenant d√©ploy√©e sur Kubernetes avec :
- ‚úÖ Haute disponibilit√© (2 replicas)
- ‚úÖ Health checks configur√©s
- ‚úÖ Configuration et secrets g√©r√©s
- ‚úÖ Auto-scaling optionnel (HPA)
- ‚úÖ Serveur MLflow int√©gr√©
- ‚úÖ Documentation compl√®te

Le projet est pr√™t pour la Phase 6 (Observabilit√© & Monitoring) !
