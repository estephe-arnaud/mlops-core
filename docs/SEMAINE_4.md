# ğŸŸ¡ Semaine 4 : MLOps Local (MLflow + DVC)

## ğŸ¯ Objectif de la Semaine

**Traquer et versionner les expÃ©riences ML localement pour la reproductibilitÃ©**

### â“ Questions ClÃ©s
- Comment tracer les expÃ©riences (MLflow) ?
- Comment versionner le dataset et le pipeline (DVC) ?

### â±ï¸ RÃ©partition des Heures (20h)
- **7h** â†’ IntÃ©grer MLflow Tracking pour logguer les hyperparamÃ¨tres, mÃ©triques et le modÃ¨le
- **7h** â†’ ImplÃ©menter DVC pour versionner le dataset et le pipeline de prÃ©-traitement
- **6h** â†’ Finalisation Projet 1 : documentation + vidÃ©o dÃ©mo

## ğŸ“‹ TÃ¢ches Ã  Accomplir

### 1. ğŸ“Š MLflow Tracking
- IntÃ©grer MLflow dans le script d'entraÃ®nement (src/training/train.py)
- Logger les hyperparamÃ¨tres et mÃ©triques
- Sauvegarder les modÃ¨les et artifacts
- Interface web MLflow UI

### 2. ğŸ”„ DVC (Data Version Control)
- Initialiser DVC dans le projet
- Versionner le dataset Iris
- CrÃ©er un pipeline de prÃ©-traitement
- GÃ©rer les dÃ©pendances entre Ã©tapes

### 3. ğŸ“š Documentation et DÃ©mo
- RÃ©diger un README complet
- CrÃ©er des schÃ©mas d'architecture
- Enregistrer une vidÃ©o de dÃ©monstration
- Finaliser le Projet 1

## ğŸ“¦ Livrables Attendus

### Structure MLflow
```
mlruns/                    # Dossier MLflow (gÃ©nÃ©rÃ©)
â”œâ”€â”€ 0/                    # Experiments
â”‚   â””â”€â”€ runs/             # Runs individuels
â””â”€â”€ models/               # ModÃ¨les enregistrÃ©s
```

### Structure DVC
```
.dvc/                     # Configuration DVC
â”œâ”€â”€ config               # Configuration
â”œâ”€â”€ cache/               # Cache des donnÃ©es
â””â”€â”€ tmp/                 # Fichiers temporaires

data/                    # DonnÃ©es versionnÃ©es
â”œâ”€â”€ raw/                 # DonnÃ©es brutes
â”œâ”€â”€ processed/           # DonnÃ©es traitÃ©es
â””â”€â”€ .gitignore          # Ignorer les gros fichiers

dvc.yaml                 # Pipeline DVC
dvc.lock                 # Verrouillage des versions
```

### Documentation
- **README.md** : Documentation complÃ¨te du projet
- **ARCHITECTURE.md** : SchÃ©mas et architecture
- **DEMO_VIDEO.mp4** : VidÃ©o de dÃ©monstration (3-5 min)

## ğŸš€ ImplÃ©mentation PrÃ©vue

### MLflow Integration
```python
# src/training/train.py avec MLflow
import mlflow
import mlflow.sklearn

def train_model():
    with mlflow.start_run():
        # Log des paramÃ¨tres
        mlflow.log_param("algorithm", "RandomForest")
        mlflow.log_param("n_estimators", 100)
        mlflow.log_param("max_depth", 10)
        
        # EntraÃ®nement du modÃ¨le
        model = RandomForestClassifier(n_estimators=100, max_depth=10)
        model.fit(X_train, y_train)
        
        # Ã‰valuation
        accuracy = model.score(X_test, y_test)
        mlflow.log_metric("accuracy", accuracy)
        
        # Sauvegarde du modÃ¨le
        mlflow.sklearn.log_model(model, "model")
        
        return model
```

### DVC Pipeline
```yaml
# dvc.yaml
stages:
  prepare:
    cmd: python -m src.data.prepare
    deps:
    - data/raw/iris.csv
    outs:
    - data/processed/train.csv
    - data/processed/test.csv
    
  train:
    cmd: python -m src.training.train
    deps:
    - data/processed/train.csv
    - data/processed/test.csv
    - src/training/train.py
    - src/evaluation/evaluate.py
    outs:
    - models/iris_model.pkl
    - models/metadata.json
    metrics:
    - models/metrics.json
```

## ğŸ› ï¸ Outils Ã  Utiliser

### MLflow
- **Tracking** : Logging des expÃ©riences
- **Models** : Gestion des modÃ¨les
- **UI** : Interface web pour visualisation
- **Storage** : Fichier local (puis cloud)

### DVC
- **Data Versioning** : Git-like pour les donnÃ©es
- **Pipeline** : Orchestration des Ã©tapes
- **Cache** : Stockage efficace
- **Remote** : Stockage distant (optionnel)

### Visualisation
- **MLflow UI** : Interface web des expÃ©riences
- **DVC Plots** : Visualisation des mÃ©triques
- **Draw.io** : SchÃ©mas d'architecture

## ğŸ“Š MÃ©triques Attendues

| Composant | Objectif |
|-----------|----------|
| **MLflow Runs** | 5+ expÃ©riences loggÃ©es |
| **DVC Pipeline** | 2+ Ã©tapes (prepare, train) |
| **Data Versioning** | Dataset et modÃ¨les versionnÃ©s |
| **ReproductibilitÃ©** | Pipeline reproductible |

## ğŸ”— Ressources

- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [DVC Documentation](https://dvc.org/doc)
- [MLflow Quickstart](https://mlflow.org/docs/latest/getting-started/index.html)
- [DVC Tutorial](https://dvc.org/doc/start)

## ğŸ“ˆ Progression

### Phase 1 : MLflow (7h)
- [ ] Installation et configuration MLflow
- [ ] IntÃ©gration dans src/training/train.py
- [ ] Logging des paramÃ¨tres et mÃ©triques
- [ ] Sauvegarde des modÃ¨les
- [ ] Interface web MLflow UI

### Phase 2 : DVC (7h)
- [ ] Installation et initialisation DVC
- [ ] Versioning du dataset
- [ ] CrÃ©ation du pipeline dvc.yaml
- [ ] Gestion des dÃ©pendances
- [ ] Tests de reproductibilitÃ©

### Phase 3 : Finalisation (6h)
- [ ] Documentation complÃ¨te
- [ ] SchÃ©mas d'architecture
- [ ] VidÃ©o de dÃ©monstration
- [ ] Validation du Projet 1

## ğŸ¯ Objectifs de Validation

- [ ] MLflow UI accessible et fonctionnel
- [ ] ExpÃ©riences loggÃ©es avec paramÃ¨tres/mÃ©triques
- [ ] DVC pipeline reproductible
- [ ] Dataset et modÃ¨les versionnÃ©s
- [ ] Documentation complÃ¨te
- [ ] VidÃ©o de dÃ©monstration enregistrÃ©e

## ğŸ“Š Interface MLflow

### FonctionnalitÃ©s Ã  ImplÃ©menter
- **Experiments** : Organisation des runs
- **Runs** : DÃ©tails de chaque expÃ©rience
- **Models** : Gestion des modÃ¨les
- **Artifacts** : Fichiers associÃ©s
- **Metrics** : Graphiques des mÃ©triques

### MÃ©triques Ã  Logger
- **Accuracy** : PrÃ©cision du modÃ¨le
- **Precision** : PrÃ©cision par classe
- **Recall** : Rappel par classe
- **F1-Score** : Score F1 par classe
- **Confusion Matrix** : Matrice de confusion

## ğŸ”„ Pipeline DVC

### Ã‰tapes du Pipeline
1. **Prepare** : PrÃ©paration des donnÃ©es
2. **Train** : EntraÃ®nement du modÃ¨le
3. **Evaluate** : Ã‰valuation et mÃ©triques
4. **Deploy** : PrÃ©paration du dÃ©ploiement

### Gestion des DÃ©pendances
- **Data** : Dataset â†’ Train/Test
- **Model** : Train â†’ Model + Metadata
- **Metrics** : Evaluate â†’ Metrics JSON

## ğŸš€ Prochaines Ã‰tapes (Phase 2)

- â˜ï¸ DÃ©ploiement cloud avec Vertex AI
- ğŸ³ Orchestration Kubernetes
- ğŸ“Š Monitoring et observabilitÃ©
- ğŸ” SÃ©curitÃ© et conformitÃ©

## ğŸ“š Documentation Ã  CrÃ©er

### README Principal
- Vue d'ensemble du projet
- Instructions d'installation
- Guide d'utilisation
- Architecture et schÃ©mas

### Documentation Technique
- Configuration MLflow
- Pipeline DVC
- ProcÃ©dures de dÃ©ploiement
- Troubleshooting

### VidÃ©o de DÃ©monstration
- **DurÃ©e** : 3-5 minutes
- **Contenu** : Installation, utilisation, rÃ©sultats
- **Format** : Loom ou OBS Studio
- **Objectif** : DÃ©monstration complÃ¨te du Projet 1

---

---

## âœ… ImplÃ©mentation ComplÃ¨te

### Phase 1 : MLflow Tracking âœ…

#### Installation
MLflow a Ã©tÃ© ajoutÃ© aux dÃ©pendances dans `pyproject.toml` :
```toml
mlflow = "^2.9.2"
```

#### IntÃ©gration dans training/train.py
Le script `src/training/train.py` a Ã©tÃ© modifiÃ© pour intÃ©grer MLflow :

**FonctionnalitÃ©s implÃ©mentÃ©es** :
- âœ… Tracking des hyperparamÃ¨tres (n_estimators, max_depth, random_state, test_size)
- âœ… Logging des mÃ©triques globales (accuracy, precision, recall, f1-score)
- âœ… Logging des mÃ©triques par classe (precision, recall, f1-score pour chaque classe)
- âœ… Sauvegarde de la confusion matrix comme artifact
- âœ… Enregistrement du modÃ¨le via `mlflow.sklearn.log_model()`
- âœ… Sauvegarde des mÃ©tadonnÃ©es comme artifact JSON

**Utilisation** :
```python
from src.training.train import train_model

# Avec MLflow (par dÃ©faut)
model, metadata = train_model(n_estimators=100, max_depth=10)

# Sans MLflow
model, metadata = train_model(use_mlflow=False)
```

#### Interface MLflow UI
Lancer l'interface web :
```bash
make mlflow-ui
# Ou directement
poetry run mlflow ui --host 127.0.0.1 --port 5000
```

AccÃ¨s : http://localhost:5000

**FonctionnalitÃ©s disponibles** :
- Visualisation des expÃ©riences
- Comparaison des runs
- Graphiques des mÃ©triques
- TÃ©lÃ©chargement des modÃ¨les
- Visualisation des artifacts

### Phase 2 : DVC Pipeline âœ…

#### Installation
DVC a Ã©tÃ© ajoutÃ© aux dÃ©pendances dans `pyproject.toml` :
```toml
dvc = {extras = ["gs", "s3", "azure", "oss", "ssh", "hdfs", "webdav", "gdrive"], version = "^3.41.0"}
```

#### Structure des donnÃ©es
```
data/
â”œâ”€â”€ raw/              # Dataset brut (versionnÃ© avec DVC)
â”‚   â””â”€â”€ iris.csv
â””â”€â”€ processed/        # DonnÃ©es traitÃ©es (gÃ©nÃ©rÃ©es)
    â”œâ”€â”€ train.csv
    â””â”€â”€ test.csv
```

#### Script de prÃ©paration
Le script `src/data/prepare.py` :
- Charge le dataset Iris depuis scikit-learn
- CrÃ©e un DataFrame pandas
- Lit les paramÃ¨tres depuis `params.yaml` via `src/config.py` (validation Pydantic)
- Divise en train/test avec les paramÃ¨tres configurÃ©s
- Sauvegarde dans `data/raw/` et `data/processed/`

#### Configuration centralisÃ©e
Le module `src/config.py` :
- Lit et valide les paramÃ¨tres depuis `params.yaml` avec Pydantic
- Validation type-safe des hyperparamÃ¨tres et paramÃ¨tres de donnÃ©es
- Valeurs par dÃ©faut si `params.yaml` est absent
- Pattern singleton pour Ã©viter les rechargements multiples

#### Pipeline DVC
Le fichier `dvc.yaml` dÃ©finit le pipeline :

**Ã‰tape 1 : Prepare**
- Commande : `poetry run python -m src.data.prepare`
- DÃ©pendances : `src/data/prepare.py`, `src/config.py`
- ParamÃ¨tres : `data.test_size`, `data.random_state` (depuis `params.yaml`)
- Sorties : `data/raw/iris.csv`, `data/processed/train.csv`, `data/processed/test.csv`

**Ã‰tape 2 : Train**
- Commande : `poetry run python -m src.training.train`
- DÃ©pendances : `data/processed/train.csv`, `data/processed/test.csv`, `src/training/train.py`, `src/evaluation/evaluate.py`, `src/config.py`
- ParamÃ¨tres : `train.n_estimators`, `train.max_depth`, `train.random_state`, `train.test_size` (depuis `params.yaml`)
- Sorties : `models/iris_model.pkl`, `models/metadata.json`
- MÃ©triques : `models/metrics.json`

#### Commandes DVC

**Initialisation** :
```bash
make dvc-init
# Ou directement
poetry run dvc init
```

**ExÃ©cution du pipeline** :
```bash
make dvc-repro
# Ou directement
poetry run dvc repro
```

**VÃ©rifier l'Ã©tat** :
```bash
make dvc-status
# Ou directement
poetry run dvc status
```

**Visualiser le pipeline** :
```bash
make dvc-pipeline
# Ou directement
poetry run dvc dag
```

### Phase 3 : IntÃ©gration ComplÃ¨te âœ…

#### Configuration centralisÃ©e avec Pydantic âœ…
Le module `src/config.py` a Ã©tÃ© crÃ©Ã© pour :
- âœ… Lire et valider les paramÃ¨tres depuis `params.yaml`
- âœ… Validation type-safe avec Pydantic (contraintes, types)
- âœ… Gestion d'erreurs robuste avec valeurs par dÃ©faut
- âœ… Pattern singleton pour performance
- âœ… Factorisation des paramÃ¨tres communs (DRY)

#### Scripts amÃ©liorÃ©s
Les scripts `prepare.py` et `train.py` :
- âœ… Utilisent `get_config()` pour lire les paramÃ¨tres depuis `params.yaml`
- âœ… ParamÃ¨tres surchargeables en arguments si nÃ©cessaire
- âœ… Logging structurÃ© pour traÃ§abilitÃ©
- âœ… Compatible avec MLflow et DVC simultanÃ©ment

#### Commandes Makefile
Nouvelles commandes ajoutÃ©es :

**MLflow** :
- `make mlflow-ui` : Lancer l'interface MLflow
- `make mlflow-experiments` : Lister les expÃ©riences

**DVC** :
- `make dvc-init` : Initialiser DVC
- `make dvc-repro` : RÃ©exÃ©cuter le pipeline
- `make dvc-status` : VÃ©rifier l'Ã©tat
- `make dvc-push` : Pousser les donnÃ©es (si remote configurÃ©)
- `make dvc-pull` : TÃ©lÃ©charger les donnÃ©es
- `make dvc-pipeline` : Afficher le pipeline

## ğŸš€ Guide d'Utilisation

### Workflow Complet

#### 1. Installation
```bash
# Installer les dÃ©pendances (inclut MLflow et DVC)
make install
```

#### 2. PrÃ©parer les donnÃ©es (DVC)
```bash
# ExÃ©cuter l'Ã©tape prepare du pipeline
poetry run dvc repro prepare

# Ou exÃ©cuter directement
poetry run python -m src.data.prepare
```

#### 3. EntraÃ®ner le modÃ¨le avec MLflow
```bash
# EntraÃ®ner avec tracking MLflow
make train

# Ou avec des hyperparamÃ¨tres personnalisÃ©s
poetry run python -c "
from src.training.train import train_model
train_model(n_estimators=150, max_depth=15)
"
```

#### 4. Visualiser les rÃ©sultats
```bash
# Lancer MLflow UI
make mlflow-ui

# Ouvrir http://localhost:5000 dans le navigateur
```

#### 5. ExÃ©cuter le pipeline complet (DVC)
```bash
# ExÃ©cuter toutes les Ã©tapes
make dvc-repro

# VÃ©rifier l'Ã©tat
make dvc-status
```

### Exemples d'ExpÃ©riences MLflow

#### ExpÃ©rience 1 : ModÃ¨le de base
```bash
poetry run python -c "
from src.training.train import train_model
train_model(n_estimators=100, max_depth=None)
"
```

#### ExpÃ©rience 2 : ModÃ¨le avec profondeur limitÃ©e
```bash
poetry run python -c "
from src.training.train import train_model
train_model(n_estimators=100, max_depth=5)
"
```

#### ExpÃ©rience 3 : Plus d'arbres
```bash
poetry run python -c "
from src.training.train import train_model
train_model(n_estimators=200, max_depth=10)
"
```

### Versioning des DonnÃ©es (DVC)

#### Ajouter des donnÃ©es au tracking
```bash
# Ajouter le dataset brut
poetry run dvc add data/raw/iris.csv

# Commit dans Git
git add data/raw/iris.csv.dvc .gitignore
git commit -m "Add iris dataset"
```

#### Changer de version de donnÃ©es
```bash
# Modifier les donnÃ©es
# ...

# Mettre Ã  jour DVC
poetry run dvc add data/raw/iris.csv

# Commit
git add data/raw/iris.csv.dvc
git commit -m "Update dataset version"
```

## ğŸ“Š RÃ©sultats Attendus

### MLflow
- âœ… ExpÃ©riences loggÃ©es dans `mlruns/`
- âœ… ModÃ¨les enregistrÃ©s et versionnÃ©s
- âœ… MÃ©triques tracÃ©es et comparables
- âœ… Interface web fonctionnelle

### DVC
- âœ… Pipeline reproductible
- âœ… DonnÃ©es versionnÃ©es
- âœ… DÃ©pendances gÃ©rÃ©es automatiquement
- âœ… Cache pour accÃ©lÃ©rer les rÃ©exÃ©cutions

## ğŸ” DÃ©pannage

### MLflow UI ne dÃ©marre pas
```bash
# VÃ©rifier que MLflow est installÃ©
poetry run mlflow --version

# VÃ©rifier le port 5000
lsof -i :5000

# Utiliser un autre port
poetry run mlflow ui --port 5001
```

### DVC pipeline Ã©choue
```bash
# VÃ©rifier que les dÃ©pendances existent
poetry run dvc status

# Nettoyer et rÃ©exÃ©cuter
poetry run dvc repro --force
```

### DonnÃ©es non trouvÃ©es
```bash
# VÃ©rifier que prepare a Ã©tÃ© exÃ©cutÃ©
ls -la data/processed/

# RÃ©exÃ©cuter prepare
poetry run dvc repro prepare
```

## âœ… Validation des Objectifs

| Objectif | Status | DÃ©tails |
|----------|--------|---------|
| **MLflow Tracking** | âœ… | IntÃ©gration complÃ¨te avec logging paramÃ¨tres/mÃ©triques |
| **MLflow UI** | âœ… | Interface web fonctionnelle |
| **DVC Pipeline** | âœ… | Pipeline Ã  2 Ã©tapes (prepare, train) |
| **Versioning DonnÃ©es** | âœ… | Dataset versionnÃ© avec DVC |
| **ReproductibilitÃ©** | âœ… | Pipeline reproductible |
| **Documentation** | âœ… | Guide complet dans ce fichier |

---

**ğŸ‰ Semaine 4 terminÃ©e avec succÃ¨s !**

Le projet dispose maintenant de :
- âœ… Tracking complet des expÃ©riences ML avec MLflow
- âœ… Versioning des donnÃ©es et pipeline reproductible avec DVC
- âœ… Documentation complÃ¨te et guide d'utilisation

Le Projet 1 est maintenant finalisÃ© et prÃªt pour la dÃ©monstration !
